{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted /data/share/project/smart_hospital/medical_dataset/doc_check/01_raw/dataset_doccheck.json to /data/share/project/smart_hospital/medical_dataset/doc_check/01_raw/doc_check.jsonl.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Define the directories and file names\n",
    "doc_check_dir = '/data/share/project/smart_hospital/medical_dataset/doc_check/01_raw'\n",
    "raw_dir = '/data/share/project/smart_hospital/medical_dataset/doc_check/01_raw'\n",
    "\n",
    "json_file_path = os.path.join(doc_check_dir, 'dataset_doccheck.json')\n",
    "jsonl_file_path = os.path.join(raw_dir, 'doc_check.jsonl')\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "# Write the JSONL file\n",
    "with open(jsonl_file_path, 'w') as jsonl_file:\n",
    "    for item in json_data:\n",
    "        jsonl_file.write(json.dumps(item) + '\\n')\n",
    "\n",
    "print(f\"Converted {json_file_path} to {jsonl_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read items from /data/share/project/smart_hospital/medical_dataset/doc_check/01_raw/original/dataset_doccheck.json.\n",
      "Converted /data/share/project/smart_hospital/medical_dataset/doc_check/01_raw/original/dataset_doccheck.json to /data/share/project/smart_hospital/medical_dataset/doc_check/01_raw/original/doc_check.jsonl.\n",
      "Wrote 13136 items to /data/share/project/smart_hospital/medical_dataset/doc_check/01_raw/original/doc_check.jsonl.\n"
     ]
    }
   ],
   "source": [
    "######### doc_check file converted from json to jsonl ###########\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Define the directories and file names\n",
    "doc_check_dir = '/data/share/project/smart_hospital/medical_dataset/doc_check/01_raw/original'\n",
    "raw_dir = '/data/share/project/smart_hospital/medical_dataset/doc_check/01_raw/original'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(doc_check_dir, exist_ok=True)\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "\n",
    "json_file_path = os.path.join(doc_check_dir, 'dataset_doccheck.json')\n",
    "jsonl_file_path = os.path.join(raw_dir, 'doc_check.jsonl')\n",
    "\n",
    "# Initialize counter for written items\n",
    "written_items = 0\n",
    "\n",
    "try:\n",
    "    # Read the JSON file\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    print(f\"Read items from {json_file_path}.\")\n",
    "    \n",
    "    # Validate that json_data is a dictionary\n",
    "    if not isinstance(json_data, dict):\n",
    "        print(\"The JSON data is not a dictionary. Exiting.\")\n",
    "        exit(1)\n",
    "\n",
    "    # Write the JSONL file\n",
    "    with open(jsonl_file_path, 'w') as jsonl_file:\n",
    "        for key, value in json_data.items():\n",
    "            # Remove all white-spaces from the value\n",
    "            value_no_whitespace = ''.join(value.split())\n",
    "            \n",
    "            # Transform the data into the desired format\n",
    "            json_object = {\"text\": value_no_whitespace, \"id\": key}\n",
    "            \n",
    "            # Write the transformed JSON object to the JSONL file\n",
    "            jsonl_file.write(json.dumps(json_object) + '\\n')\n",
    "            written_items += 1\n",
    "    \n",
    "    print(f\"Converted {json_file_path} to {jsonl_file_path}.\")\n",
    "    print(f\"Wrote {written_items} items to {jsonl_file_path}.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "except PermissionError as e:\n",
    "    print(f\"Permission error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def convert_json_to_jsonl(json_dir, output_jsonl_path):\n",
    "    \"\"\"\n",
    "    Convert multiple JSON files in a directory to a single JSONL file.\n",
    "\n",
    "    Parameters:\n",
    "        json_dir (str): The directory containing the JSON files to convert.\n",
    "        output_jsonl_path (str): The path where the output JSONL file will be saved.\n",
    "    \"\"\"\n",
    "    # Ensure the provided directory exists\n",
    "    if not os.path.exists(json_dir):\n",
    "        print(f\"The directory {json_dir} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Initialize an empty list to store the JSONL lines\n",
    "    jsonl_lines = []\n",
    "    \n",
    "    # Iterate through each file in the directory\n",
    "    for filename in os.listdir(json_dir):\n",
    "        # Only process files with a .json extension\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(json_dir, filename)\n",
    "            \n",
    "            # Read the JSON file\n",
    "            with open(filepath, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            # Convert each key-value pair to a JSONL-compatible line\n",
    "            for key, value in json_data.items():\n",
    "                jsonl_line = json.dumps({\"text\": value, \"id\": key})  # Use 'value' directly\n",
    "                jsonl_lines.append(jsonl_line)\n",
    "                \n",
    "    # Write the JSONL lines to the output file\n",
    "    with open(output_jsonl_path, 'w') as f:\n",
    "        for line in jsonl_lines:\n",
    "            f.write(line + '\\n')\n",
    "\n",
    "# Directory and output path\n",
    "json_dir = '/data/share/project/smart_hospital/medical_dataset/springer_jsons/01_raw/original/'\n",
    "output_jsonl_path = '/data/share/project/smart_hospital/medical_dataset/springer_jsons/01_raw/Springer_dataset.jsonl'\n",
    "\n",
    "# Call the conversion function\n",
    "convert_json_to_jsonl(json_dir, output_jsonl_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted the text to JSONL format. The output file is saved at /data/share/project/smart_hospital/medical_dataset/kres/01_raw/kres_dataset.jsonl.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to convert a text with multiple paragraphs to a single JSONL file\n",
    "def convert_text_to_jsonl(text, output_jsonl_path):\n",
    "    \"\"\"\n",
    "    Convert a text with multiple paragraphs to a single JSONL file.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text containing multiple paragraphs.\n",
    "        output_jsonl_path (str): The path where the output JSONL file will be saved.\n",
    "    \"\"\"\n",
    "    # Split the text into paragraphs based on line breaks\n",
    "    paragraphs = text.split('\\n')\n",
    "    \n",
    "    # Initialize an empty list to store the JSONL lines\n",
    "    jsonl_lines = []\n",
    "    \n",
    "    # Convert each paragraph to a JSONL-compatible line\n",
    "    for idx, paragraph in enumerate(paragraphs):\n",
    "        # Remove whitespace\n",
    "        paragraph_no_whitespace = ''.join(paragraph.split())\n",
    "        # Create a JSONL line\n",
    "        jsonl_line = json.dumps({\"text\": paragraph_no_whitespace, \"id\": str(idx + 1)})\n",
    "        jsonl_lines.append(jsonl_line)\n",
    "    \n",
    "    # Combine JSONL lines into a single JSONL string\n",
    "    jsonl_content = '\\n'.join(jsonl_lines)\n",
    "    \n",
    "    # Save the JSONL content to the specified file\n",
    "    with open(output_jsonl_path, 'w') as f:\n",
    "        f.write(jsonl_content)\n",
    "\n",
    "# Sample usage\n",
    "text = \"\"\"Your sample text here separated by line breaks for each paragraph.\"\"\"\n",
    "\n",
    "output_jsonl_path = '/data/share/project/smart_hospital/medical_dataset/kres/01_raw/kres_dataset.jsonl'\n",
    "\n",
    "convert_text_to_jsonl(text, output_jsonl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to read text from a file\n",
    "def read_text_from_file(input_file_path):\n",
    "    with open(input_file_path, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "# Function to convert a text with multiple paragraphs to a single JSONL file\n",
    "def convert_text_to_jsonl(text, output_jsonl_path):\n",
    "    paragraphs = text.split('\\n')\n",
    "    jsonl_lines = []\n",
    "    for idx, paragraph in enumerate(paragraphs):\n",
    "        jsonl_line = json.dumps({\"text\": paragraph, \"id\": str(idx + 1)})\n",
    "        jsonl_lines.append(jsonl_line)\n",
    "    \n",
    "    jsonl_content = '\\n'.join(jsonl_lines)\n",
    "    \n",
    "    with open(output_jsonl_path, 'w') as f:\n",
    "        f.write(jsonl_content)\n",
    "\n",
    "input_file_path = '/data/share/project/smart_hospital/medical_dataset/kres/01_raw/khresmoi-summary-dev.de'\n",
    "\n",
    "output_jsonl_path = '/data/share/project/smart_hospital/medical_dataset/kres/01_raw/kres_dataset.jsonl'\n",
    "\n",
    "text = read_text_from_file(input_file_path)\n",
    "\n",
    "# Convert the text to JSONL and save it\n",
    "convert_text_to_jsonl(text, output_jsonl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"BeiderTyp-2-Infektion(einerGangr\\u00e4ndurchh\\u00e4molysierendeStreptokokken)tretendieGruppe-A-Streptokokken(GAS)isoliertoderinKombinationmitanderenSpezies,\\u00fcblicherweiseinVerbindungmitdemStaphylococcusaureus,auf.\", \"id\": \"1\"}\n",
      "\n",
      "{\"text\": \"DieverwendeteStrahlungsmengef\\u00fcreinenR\\u00f6ntgen-Thoraxistsehrgering.\", \"id\": \"2\"}\n",
      "\n",
      "{\"text\": \"DieMeningokokken-ErkrankungisteineernsthafteBakterieninfektion,diezuSchwellungenimGehirnundR\\u00fcckenmarksowiezurEntz\\u00fcndungdesBlutsundandererOrganef\\u00fchrenkann.\", \"id\": \"3\"}\n",
      "\n",
      "{\"text\": \"BeschwerdenimZusammenhangmitnekrotisierenderZellulitisundnekrotisierenderFasziitiswerdenhierbesprochen.\", \"id\": \"4\"}\n",
      "\n",
      "{\"text\": \"Empf\\u00e4ngervonOrgantransplantatenzeigeneinerh\\u00f6htesRisikof\\u00fcrdieInfektiondurchNTMaufgrundeinergeschw\\u00e4chten,zellvermitteltenImmunabwehr,dennochtretenNTM-InfektionenindieserPopulationrelativseltenauf.\", \"id\": \"5\"}\n",
      "\n",
      "{\"text\": \"WokannichInformationenzurDiagnosederGaucher-KrankheitoderzumUmgangdamitfinden?\", \"id\": \"6\"}\n",
      "\n",
      "{\"text\": \"DaherentwickeltsichbeieinemMangelanVitaminD1,25-OHHypokalz\\u00e4mie,diezueiner\\u00fcberm\\u00e4\\u00dfigenAussch\\u00fcttungvonParathormonf\\u00fchrt.\", \"id\": \"7\"}\n",
      "\n",
      "{\"text\": \"DiesesGenliefertInstruktionenzurHerstellungeinesEnzymsnamensNeuraminidase1(NEU1),dasinLysosomenzufindenist.\", \"id\": \"8\"}\n",
      "\n",
      "{\"text\": \"SDHbeiKindernunterscheidetsichdeutlichvonSDHbeiErwachsenen,daKopfverletzungeneineverbreiteteUrsachesind,vorallembeip\\u00e4driatischenPatientenunterzweiJahren.\", \"id\": \"9\"}\n",
      "\n",
      "{\"text\": \"VaskulitiskanndieBlutgef\\u00e4\\u00dfejeglicherGr\\u00f6\\u00dfe,jeglichenTypsundLokationbefallenundsomitDysfunktionenjedesOrgansystemseinschlie\\u00dflichdeszentralenundperipherenNervensystemshervorrufen.\", \"id\": \"10\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 10  # Number of lines to read\n",
    "with open('/data/share/project/smart_hospital/medical_dataset/kres/01_raw/kres_dataset.jsonl', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= n:\n",
    "            break\n",
    "        print(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential ID assignment completed. Updated files are in /home/IAIS/jdatta/output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Input and output directories\n",
    "input_dir = \"/home/IAIS/jdatta/output\"\n",
    "output_dir = \"/home/IAIS/jdatta/output\"\n",
    "\n",
    "# Initialize a counter for unique document IDs\n",
    "document_id_counter = 0  # Start from 1\n",
    "\n",
    "# Process each JSONL file in the input directory in sorted order (to ensure we start with file 0)\n",
    "for filename in sorted(os.listdir(input_dir)):\n",
    "    if filename.endswith(\".jsonl\"):\n",
    "        input_file_path = os.path.join(input_dir, filename)\n",
    "        output_file_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        with open(input_file_path, \"r\", encoding=\"utf-8\") as input_file, open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "            for line in input_file:\n",
    "                data = json.loads(line)\n",
    "                \n",
    "                # Assign the current document ID counter value and then increment it\n",
    "                data[\"id\"] = str(document_id_counter)  # Using str() to ensure the ID is a string. Remove if you prefer integer IDs.\n",
    "                document_id_counter += 1\n",
    "                \n",
    "                output_file.write(json.dumps(data, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Sequential ID assignment completed. Updated files are in\", output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read items from /data/share/project/smart_hospital/medical_dataset/doc_check/01_raw/original/dataset_doccheck.json.\n",
      "Converted /data/share/project/smart_hospital/medical_dataset/doc_check/01_raw/original/dataset_doccheck.json to /data/share/project/smart_hospital/medical_dataset/doc_check/01_raw/original/doc_check.jsonl.\n",
      "Wrote 13136 items to /data/share/project/smart_hospital/medical_dataset/doc_check/01_raw/original/doc_check.jsonl.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Define the directories and file names\n",
    "doc_check_dir = '/home/IAIS/jdatta/output'\n",
    "#raw_dir = '/data/share/project/smart_hospital/medical_dataset/doc_check/01_raw/original'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(doc_check_dir, exist_ok=True)\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "\n",
    "json_file_path = os.path.join(doc_check_dir, 'forum_data_0.json')\n",
    "jsonl_file_path = os.path.join(raw_dir, 'forum_data_0.jsonl')\n",
    "\n",
    "# Initialize counter for written items\n",
    "written_items = 0\n",
    "\n",
    "try:\n",
    "    # Read the JSON file\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    print(f\"Read items from {json_file_path}.\")\n",
    "    \n",
    "    # Validate that json_data is a dictionary\n",
    "    if not isinstance(json_data, dict):\n",
    "        print(\"The JSON data is not a dictionary. Exiting.\")\n",
    "        exit(1)\n",
    "\n",
    "    # Write the JSONL file\n",
    "    with open(jsonl_file_path, 'w') as jsonl_file:\n",
    "        for key, value in json_data.items():\n",
    "            \n",
    "            # Transform the data into the desired format\n",
    "            json_object = {\"text\": value, \"id\": key}\n",
    "            \n",
    "            # Write the transformed JSON object to the JSONL file\n",
    "            jsonl_file.write(json.dumps(json_object) + '\\n')\n",
    "            written_items += 1\n",
    "    \n",
    "    print(f\"Converted {json_file_path} to {jsonl_file_path}.\")\n",
    "    print(f\"Wrote {written_items} items to {jsonl_file_path}.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "except PermissionError as e:\n",
    "    print(f\"Permission error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read items from /data/share/project/smart_hospital/medical_dataset/ufal/dataset_ufal.json.\n",
      "Converted /data/share/project/smart_hospital/medical_dataset/ufal/dataset_ufal.json to /data/share/project/smart_hospital/medical_dataset/ufal/01_raw/ufal.jsonl.\n",
      "Wrote 37814533 items to /data/share/project/smart_hospital/medical_dataset/ufal/01_raw/ufal.jsonl.\n"
     ]
    }
   ],
   "source": [
    "######### Ufal ###########\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "# Define the directories and file names\n",
    "doc_check_dir = '/data/share/project/smart_hospital/medical_dataset/ufal'\n",
    "raw_dir = '/data/share/project/smart_hospital/medical_dataset/ufal/01_raw'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(doc_check_dir, exist_ok=True)\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "\n",
    "json_file_path = os.path.join(doc_check_dir, 'dataset_ufal.json')\n",
    "jsonl_file_path = os.path.join(raw_dir, 'ufal.jsonl')\n",
    "\n",
    "# Initialize counter for written items\n",
    "written_items = 0\n",
    "\n",
    "try:\n",
    "    # Read the JSON file\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    print(f\"Read items from {json_file_path}.\")\n",
    "    \n",
    "    # Validate that json_data is a dictionary\n",
    "    if not isinstance(json_data, dict):\n",
    "        print(\"The JSON data is not a dictionary. Exiting.\")\n",
    "        exit(1)\n",
    "\n",
    "    # Write the JSONL file\n",
    "    with open(jsonl_file_path, 'w') as jsonl_file:\n",
    "        for key, value in json_data.items():\n",
    "            # Transform the data into the desired format\n",
    "            json_object = {\"text\": value, \"id\": key}\n",
    "            \n",
    "            # Write the transformed JSON object to the JSONL file\n",
    "            jsonl_file.write(json.dumps(json_object) + '\\n')\n",
    "            written_items += 1\n",
    "    \n",
    "    print(f\"Converted {json_file_path} to {jsonl_file_path}.\")\n",
    "    print(f\"Wrote {written_items} items to {jsonl_file_path}.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "except PermissionError as e:\n",
    "    print(f\"Permission error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def convert_json_to_jsonl(json_file_path, jsonl_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)  # Load JSON data from file\n",
    "\n",
    "    # Assuming the relevant data is under 'board' -> 'Externe Umfragen/Studien'\n",
    "    posts = data['board']['Externe Umfragen/Studien']\n",
    "\n",
    "    with open(jsonl_file_path, 'w') as jsonl_file:\n",
    "        for post in posts:\n",
    "            jsonl_file.write(json.dumps(post) + '\\n')\n",
    "\n",
    "# Example usage\n",
    "convert_json_to_jsonl('/home/IAIS/jdatta/output/forum_data_0.json', '/home/IAIS/jdatta/output/output.jsonl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file_path = \"/home/IAIS/jdatta/output/output.jsonl\"\n",
    "output_file_path = \"/home/IAIS/jdatta/output/test-output.jsonl\"\n",
    "\n",
    "def process_line(line):\n",
    "    data = json.loads(line)\n",
    "    \n",
    "    # Extract texts from responses\n",
    "    responses_texts = [resp[\"text\"] for resp in data[\"responses\"].values()]\n",
    "\n",
    "    # Merge author's post text with responses texts\n",
    "    full_text = data[\"author_post\"][\"text\"] + \" \" + \" \".join(responses_texts)\n",
    "    \n",
    "    # Reformatted data keeping the necessary structure\n",
    "    reformatted_data = {\n",
    "        \"Betreff / Begonnen von\": data[\"Betreff / Begonnen von\"],\n",
    "        \"text\": full_text\n",
    "    }\n",
    "    return reformatted_data\n",
    "\n",
    "with open(input_file_path, 'r') as input_file, open(output_file_path, 'w') as output_file:\n",
    "    for line in input_file:\n",
    "        reformatted_data = process_line(line)\n",
    "        json.dump(reformatted_data, output_file, ensure_ascii=False)\n",
    "        output_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
